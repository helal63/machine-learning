{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.7z', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir('../ml/datasets/speech/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pickle\n",
    "import keras\n",
    "import random\n",
    "import scipy\n",
    "\n",
    "from pathlib import Path\n",
    "from subprocess import check_output\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dict = {0: 'yes',\n",
    "               1: 'no', \n",
    "               2: 'up', \n",
    "               3: 'down', \n",
    "               4: 'left',\n",
    "               5: 'right',\n",
    "               6: 'on',\n",
    "               7: 'off',\n",
    "               8: 'stop',\n",
    "               9: 'go',\n",
    "               10: 'unknown',\n",
    "               11: 'silence'\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_path = '../ml/datasets/speech/test/audio'\n",
    "train_audio_path = '../ml/datasets/speech/train/audio'\n",
    "\n",
    "wavs = []\n",
    "\n",
    "files = os.listdir(test_audio_path)\n",
    "\n",
    "for f in files:\n",
    "    if not f.endswith('wav'):\n",
    "        continue\n",
    "    wavs.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'test': wavs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmenting\n",
    "def bandpass(sample_rate, samples):\n",
    "    \n",
    "    fs = sample_rate  # Sample frequency (Hz)\n",
    "    fl = 180.0  # Human voices range from 85 Hz to 255 Hz\n",
    "    fh = 240.0\n",
    "    Q = 1.0  # Quality factor\n",
    "    w0 = fl/(fs/2)  # Normalized Frequency\n",
    "    w1 = fh/(fs/2)\n",
    "    # Design notch filter\n",
    "    b, a = scipy.signal.butter(3, [w0, w1], btype='bandpass', analog=True)\n",
    "    samples = scipy.signal.lfilter(b,a,samples)*30\n",
    "\n",
    "    return sample_rate, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(file):\n",
    "    path = test_audio_path + '/'\n",
    "        \n",
    "    eps=1e-10\n",
    "    sample_rate, samples = wavfile.read(path + file)\n",
    "    frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n",
    "    \n",
    "    # silence can end up being empty files, in this case we can just return one second of zeros\n",
    "    if len(spectrogram.shape) < 2:\n",
    "        return np.zeros((71,129))\n",
    "    else:\n",
    "        return np.log(np.abs(spectrogram).T+eps)\n",
    "\n",
    "def stft(file):\n",
    "    path = test_audio_path + '/'\n",
    "        \n",
    "    eps=1e-10\n",
    "    sample_rate, samples = wavfile.read(path + file)\n",
    "    frequencies, times, Zxx = signal.stft(samples, sample_rate, nperseg = sample_rate/50, noverlap = sample_rate/75)\n",
    "    \n",
    "    # silence can end up being empty files, in this case we can just return one second of zeros\n",
    "    if len(Zxx.shape) < 2:\n",
    "        return np.zeros((151,161))\n",
    "    else:\n",
    "        return np.log(np.abs(Zxx).T+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    # Generates data for Keras\n",
    "    def __init__(self, list_IDs, batch_size=32, x1dim=(71,129), x2dim=(151,161), n_channels=1,\n",
    "                 n_classes=12):\n",
    "        # Initialization\n",
    "        self.x1dim = x1dim\n",
    "        self.x2dim = x2dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate one batch of data\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X1, X2 = self.__data_generation(list_IDs_temp)\n",
    "        return [X1,X2]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        # Generates data containing batch_size samples # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "\n",
    "        X1 = np.empty((self.batch_size, *self.x1dim, self.n_channels))\n",
    "        X2 = np.empty((self.batch_size, *self.x2dim, self.n_channels))\n",
    "\n",
    "        # Generate data  \n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            spect = spectrogram(ID)\n",
    "            padded = np.zeros((self.x1dim))\n",
    "            padded[:spect.shape[0], :spect.shape[1]] = spect\n",
    "            X1[i,] = padded[:, :, np.newaxis]        \n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            trans = stft(ID)\n",
    "            #last = ID, self.dim, spect.shape\n",
    "\n",
    "            padded = np.zeros((self.x2dim))\n",
    "            padded[:trans.shape[0], :trans.shape[1]] = trans\n",
    "            X2[i,] = padded[:, :, np.newaxis]\n",
    "\n",
    "        return X1, X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "ensemble_model = load_model('../ml/models/retrained_ensemble_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "test_params = {'x1dim': (71,129),\n",
    "               'x2dim': (151,161),\n",
    "               'batch_size': 15,\n",
    "               'n_classes':12,\n",
    "               'n_channels': 1}\n",
    "\n",
    "# Generators\n",
    "test_generator = DataGenerator(test_dict['test'], **test_params)\n",
    "\n",
    "results = ensemble_model.predict_generator(test_generator, steps=3523*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat(\n",
    "    [\n",
    "        pd.Series(test_dict['test'], name='fname'),\n",
    "        pd.Series(np.argmax(results, axis=1),name='label').map(answer_dict)\n",
    "    ]\n",
    "    ,axis=1\n",
    ")\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107333\n"
     ]
    }
   ],
   "source": [
    "file = []\n",
    "label = []\n",
    "thresh = []\n",
    "for i in range(len(results)):\n",
    "    if results[i,np.argmax(results[i])] > .95:\n",
    "        file.append(test_dict['test'][i])\n",
    "        label.append(answer_dict[np.argmax(results[i])])\n",
    "print(len(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "for i in range(len(file)):\n",
    "    copyfile(test_audio_path + '/' + file[i], '../ml/datasets/speech/train/audio/' + label[i] + '/' + file[i])\n",
    "    #copyfile(test_audio_path + '/' + file[i], '../ml/speech/verify/' + label[i] + '_' + file[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e5dadd24_nohash_0.wav will be moved to silence from wow\n",
      "7014b07e_nohash_0.wav will be moved to silence from tree\n",
      "7014b07e_nohash_0.wav will be moved to silence from five\n",
      "3e7124ba_nohash_0.wav will be moved to silence from bird\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/.local/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "# any file which is all zero is obviously silence.\n",
    "from shutil import move\n",
    "\n",
    "folders = os.listdir(train_audio_path)\n",
    "for folder in folders:\n",
    "    if folder == 'silence':\n",
    "        continue\n",
    "    files = os.listdir(train_audio_path + '/' + folder)\n",
    "    for file in files:\n",
    "        if not file.endswith('wav'):\n",
    "            continue\n",
    "        try:\n",
    "            sample_rate, samples = wavfile.read(train_audio_path + '/' + folder + '/' + file)\n",
    "            if np.argmax(samples) == 0:\n",
    "                print(file, 'will be moved to silence from', folder)\n",
    "                move(\n",
    "                    train_audio_path + '/' + folder + '/' + file, \n",
    "                    train_audio_path + '/silence/' + file\n",
    "                )\n",
    "        except ValueError:\n",
    "            print(file, folder, 'had a value error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "contest_dict = {'yes': 0,\n",
    "                'no': 1,\n",
    "                'up': 2,\n",
    "                'down': 3,\n",
    "                'left': 4,\n",
    "                'right': 5,\n",
    "                'on': 6,\n",
    "                'off': 7,\n",
    "                'stop': 8,\n",
    "                'go': 9,\n",
    "                'unknown': 10,\n",
    "                'silence': 11\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 33\n"
     ]
    }
   ],
   "source": [
    "# Open test / validation lists\n",
    "test_list = open(\"../ml/datasets/speech/train/testing_list.txt\", \"r\").readlines()\n",
    "validation_list = open(\"../ml/datasets/speech/train/validation_list.txt\", \"r\").readlines()\n",
    "\n",
    "train_labels = os.listdir(train_audio_path)\n",
    "print(f'Number of labels: {len(train_labels)}')\n",
    "\n",
    "wavs = []\n",
    "labels = []\n",
    "\n",
    "# create a list of all the wav files and their labels which is NOT background noise\n",
    "for label in train_labels:\n",
    "    if label == '_background_noise_':\n",
    "        continue\n",
    "    files = os.listdir(train_audio_path + '/' + label)\n",
    "    for f in files:\n",
    "        if not f.endswith('wav'):\n",
    "            continue\n",
    "        wavs.append(f)\n",
    "        labels.append(label)\n",
    "\n",
    "x_train = []\n",
    "x_val = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_val = []\n",
    "y_test = []\n",
    "\n",
    "# sort by comparing path to list, anything not found on the lists will be used as training data\n",
    "for i in range(len(wavs)):\n",
    "\n",
    "    if any(labels[i] + '/' + wavs[i] in s for s in test_list):\n",
    "        x_test.append(wavs[i])\n",
    "        y_test.append(labels[i])\n",
    "        test_list.remove(str(labels[i] + '/' + wavs[i] + '\\n'))\n",
    "    elif any(labels[i] + '/' + wavs[i] in s for s in validation_list):\n",
    "        x_val.append(wavs[i])\n",
    "        y_val.append(labels[i])\n",
    "        validation_list.remove(str(labels[i] + '/' + wavs[i] + '\\n'))\n",
    "    else:\n",
    "        x_train.append(wavs[i])\n",
    "        y_train.append(labels[i])\n",
    "\n",
    "# format as full file path, this will be useful when using a generator to train\n",
    "x_train = [\"{}/{}\".format(y_train,x_train) for x_train, y_train in zip(x_train, y_train)]\n",
    "x_val = [\"{}/{}\".format(y_val,x_val) for x_val, y_val in zip(x_val, y_val)]\n",
    "x_test = [\"{}/{}\".format(y_test,x_test) for x_test, y_test in zip(x_test, y_test)]\n",
    "\n",
    "# overwrite labels which are not present in the contest dictionary with the string 'unknown'\n",
    "for i in range(len(y_train)):\n",
    "    if not(y_train[i] in contest_dict):\n",
    "        y_train[i] = 'unknown'\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    if not(y_val[i] in contest_dict):\n",
    "        y_val[i] = 'unknown'\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if not(y_test[i] in contest_dict):\n",
    "        y_test[i] = 'unknown'\n",
    "\n",
    "train_sequences = []\n",
    "test_sequences = []\n",
    "\n",
    "# create a list of numeric identifiers for use with NN when feeding dictionaries\n",
    "for i in range(len(y_train)):\n",
    "    train_sequences.append(contest_dict[y_train[i]])\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    train_sequences.append(contest_dict[y_val[i]])\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    test_sequences.append(contest_dict[y_test[i]])\n",
    "\n",
    "label_list = x_train + x_val\n",
    "\n",
    "# create label dictionaries\n",
    "labels = dict(zip(label_list, train_sequences))\n",
    "test_labels = dict(zip(x_test, test_sequences))\n",
    "\n",
    "# create test, train, and validation dictionaries for training and final evaluation\n",
    "test_dict = {'test': x_test}\n",
    "\n",
    "partition = {'train': x_train,\n",
    "             'validation': x_val}\n",
    "\n",
    "# pickle the results\n",
    "with open('SavedTestDict.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('SavedPartition.pickle', 'wb') as handle:\n",
    "    pickle.dump(partition, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('SavedLabels.pickle', 'wb') as handle:\n",
    "    pickle.dump(labels, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('SavedTestLabels.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_labels, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../ml/speech/SavedTestDict.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('../ml/speech/SavedPartition.pickle', 'wb') as handle:\n",
    "    pickle.dump(partition, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('../ml/speech/SavedLabels.pickle', 'wb') as handle:\n",
    "    pickle.dump(labels, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('../ml/speech/SavedTestLabels.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_labels, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46166"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
