{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['testing', 'writefile.wav', 'buffer2.wav', 'SavedPartition.pickle', 'SavedLabels.pickle', 'SavedTestLabels.pickle', 'buffer.wav', 'SavedTestDict.pickle']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../ml/speech\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pickle\n",
    "import keras\n",
    "import random\n",
    "import scipy\n",
    "import wave\n",
    "\n",
    "from pathlib import Path\n",
    "from subprocess import check_output\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_path = '../ml/datasets/speech/train/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data.\n"
     ]
    }
   ],
   "source": [
    "with open('../ml/speech/SavedPartition.pickle', 'rb') as handle:\n",
    "    partition = pickle.load(handle)\n",
    "with open('../ml/speech/SavedLabels.pickle', 'rb') as handle:\n",
    "    labels = pickle.load(handle)\n",
    "print(\"loaded data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass(sample_rate, samples):\n",
    "    \n",
    "    fs = sample_rate  # Sample frequency (Hz)\n",
    "    fl = 180.0  # Human voices range from 85 Hz to 255 Hz\n",
    "    fh = 240.0\n",
    "    Q = 1.0  # Quality factor\n",
    "    w0 = fl/(fs/2)  # Normalized Frequency\n",
    "    w1 = fh/(fs/2)\n",
    "    # Design notch filter\n",
    "    b, a = scipy.signal.butter(3, [w0, w1], btype='bandpass', analog=True)\n",
    "    samples = scipy.signal.lfilter(b,a,samples)*30\n",
    "\n",
    "    return sample_rate, samples\n",
    "\n",
    "def pitchshift(sample_rate, samples, shifthz):\n",
    "    try:\n",
    "        wavfile.write('../ml/speech/buffer.wav', sample_rate, samples)\n",
    "\n",
    "        wr = wave.open('../ml/speech/buffer.wav', 'r')\n",
    "        # Set the parameters for the output file.\n",
    "        par = list(wr.getparams())\n",
    "        par[3] = 0  # The number of samples will be set by writeframes.\n",
    "        par = tuple(par)\n",
    "        ww = wave.open('../ml/speech/writefile.wav', 'w')\n",
    "        ww.setparams(par)\n",
    "\n",
    "        fr = 20\n",
    "        sz = wr.getframerate()//fr  # Read and process 1/fr second at a time.\n",
    "        # A larger number for fr means less reverb.\n",
    "        c = int(wr.getnframes()/sz)  # count of the whole file\n",
    "        shift = shifthz//fr  # shifting 100 Hz\n",
    "\n",
    "        for num in range(c):\n",
    "\n",
    "            da = np.frombuffer(wr.readframes(sz), dtype=np.int16)\n",
    "            left, right = da[0::2], da[1::2]\n",
    "            lf, rf = np.fft.rfft(left), np.fft.rfft(right)\n",
    "            lf, rf = np.roll(lf, shift), np.roll(rf, shift)\n",
    "            lf[0:shift], rf[0:shift] = 0, 0\n",
    "            nl, nr = np.fft.irfft(lf), np.fft.irfft(rf)\n",
    "            ns = np.column_stack((nl, nr)).ravel().astype(np.int16)\n",
    "            ww.writeframes(ns.tostring())\n",
    "\n",
    "        sample_rate, samples = wavfile.read('../ml/speech/writefile.wav')\n",
    "        wr.close()\n",
    "        ww.close()\n",
    "    except:\n",
    "        return sample_rate, samples\n",
    "    return sample_rate, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(sample_rate, samples):\n",
    "    eps=1e-10\n",
    "    frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n",
    "    \n",
    "    # silence can end up being empty files, in this case we can just return one second of zeros\n",
    "    if len(spectrogram.shape) < 2:\n",
    "        return np.zeros((71,129))\n",
    "    else:\n",
    "        return np.log(np.abs(spectrogram).T+eps)\n",
    "\n",
    "def stft(sample_rate, samples):\n",
    "\n",
    "    eps=1e-10\n",
    "\n",
    "    frequencies, times, Zxx = signal.stft(samples, sample_rate, nperseg = sample_rate/50, noverlap = sample_rate/75)\n",
    "    \n",
    "    # silence can end up being empty files, in this case we can just return one second of zeros\n",
    "    if len(Zxx.shape) < 2:\n",
    "        return np.zeros((151,161))\n",
    "    else:\n",
    "        return np.log(np.abs(Zxx).T+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    # Generates data for Keras\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(151,161), x1dim=(71,129), x2dim=(151,161), n_channels=1,\n",
    "                 n_classes=11, shuffle=True, input_type='wav', testing=False, augment=True):\n",
    "        # Initialization\n",
    "        self.dim = dim\n",
    "        self.x1dim = x1dim\n",
    "        self.x2dim = x2dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.input_type = input_type\n",
    "        self.testing = testing\n",
    "        self.augment = augment\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate one batch of data\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        if self.input_type == 'all':\n",
    "            X1, X2, y = self.__data_generation(list_IDs_temp)\n",
    "            if self.testing:\n",
    "                return [X1,X2]\n",
    "            else:\n",
    "                return [X1,X2], [y]\n",
    "        else:\n",
    "            X, y = self.__data_generation(list_IDs_temp)\n",
    "            \n",
    "            return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        # Generates data containing batch_size samples # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "\n",
    "        if self.input_type == 'all':\n",
    "            X1 = np.empty((self.batch_size, *self.x1dim, self.n_channels))\n",
    "            X2 = np.empty((self.batch_size, *self.x2dim, self.n_channels))\n",
    "        else:\n",
    "            X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data  \n",
    "        if self.input_type == 'spectrogram':\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                path = train_audio_path + '/'\n",
    "                sample_rate, samples = wavfile.read(path + ID)\n",
    "\n",
    "                if self.augment:\n",
    "                    if random.randint(1,101) < 51 and len(samples)==16000:\n",
    "                        sample_rate, samples = bandpass(sample_rate, samples)\n",
    "                    if random.randint(1,101) < 51 and len(samples)==16000:\n",
    "                        shifthz = random.randint(50,200)\n",
    "                        sample_rate, samples = pitchshift(sample_rate, samples, shifthz)                        \n",
    "                trans = spectrogram(sample_rate, samples)\n",
    "                #last = ID, self.dim, spect.shape\n",
    "\n",
    "                padded = np.zeros((self.x1dim))\n",
    "                padded[:trans.shape[0], :trans.shape[1]] = trans\n",
    "                X[i,] = padded[:, :, np.newaxis]\n",
    "                y[i] = self.labels[ID]\n",
    "                \n",
    "            return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "\n",
    "        elif self.input_type == 'stft':\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                path = train_audio_path + '/'\n",
    "                sample_rate, samples = wavfile.read(path + ID)\n",
    "\n",
    "                if self.augment:\n",
    "                    if random.randint(1,101) < 51 and len(samples)==16000:\n",
    "                        sample_rate, samples = bandpass(sample_rate, samples)\n",
    "                    if random.randint(1,101) < 51 and len(samples)==16000:\n",
    "                        shifthz = random.randint(50,200)\n",
    "                        sample_rate, samples = pitchshift(sample_rate, samples, shifthz) \n",
    "                trans = stft(sample_rate, samples)\n",
    "                #last = ID, self.dim, spect.shape\n",
    "\n",
    "                padded = np.zeros((self.x2dim))\n",
    "                padded[:trans.shape[0], :trans.shape[1]] = trans\n",
    "                X[i,] = padded[:, :, np.newaxis]\n",
    "                y[i] = self.labels[ID]\n",
    "            \n",
    "            return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        \n",
    "        elif self.input_type == 'all':\n",
    "        \n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                path = train_audio_path + '/'\n",
    "                sample_rate, samples = wavfile.read(path + ID)\n",
    "\n",
    "                if self.augment:\n",
    "                    if random.randint(1,101) < 51 and len(samples)==16000:\n",
    "                        sample_rate, samples = bandpass(sample_rate, samples)\n",
    "                    if random.randint(1,101) < 51 and len(samples)==16000:\n",
    "                        shifthz = random.randint(50,200)\n",
    "                        sample_rate, samples = pitchshift(sample_rate, samples, shifthz) \n",
    "                trans = spectrogram(sample_rate, samples)\n",
    "                #last = ID, self.dim, spect.shape\n",
    "\n",
    "                padded = np.zeros((self.x1dim))\n",
    "                padded[:trans.shape[0], :trans.shape[1]] = trans\n",
    "                X1[i,] = padded[:, :, np.newaxis]\n",
    "                y[i] = self.labels[ID]\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                path = train_audio_path + '/'\n",
    "                sample_rate, samples = wavfile.read(path + ID)\n",
    "\n",
    "                if self.augment:\n",
    "                    if random.randint(1,101) < 51 and len(samples)==16000:\n",
    "                        sample_rate, samples = bandpass(sample_rate, samples)\n",
    "                    if random.randint(1,101) < 51 and len(samples)==16000:\n",
    "                        shifthz = random.randint(50,200)\n",
    "                        sample_rate, samples = pitchshift(sample_rate, samples, shifthz) \n",
    "                trans = stft(sample_rate, samples)\n",
    "                #last = ID, self.dim, spect.shape\n",
    "\n",
    "                padded = np.zeros((self.x2dim))\n",
    "                padded[:trans.shape[0], :trans.shape[1]] = trans\n",
    "                X2[i,] = padded[:, :, np.newaxis]\n",
    "                \n",
    "            return X1, X2, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "spect_model = load_model('../ml/models/spect_model.h5')\n",
    "stft_model = load_model('../ml/models/stft_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spect_model.layers.pop()\n",
    "spect_model.compile\n",
    "\n",
    "for layer in spect_model.layers:\n",
    "    layer.name = \"spect_\" + layer.name\n",
    "    \n",
    "stft_model.layers.pop()\n",
    "stft_model.compile\n",
    "\n",
    "for layer in stft_model.layers:\n",
    "    layer.name = \"stft_\" + layer.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "spect_input_1 (InputLayer)      (None, 71, 129, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spect_conv2d_1 (Conv2D)         (None, 69, 127, 32)  320         spect_input_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stft_input_1 (InputLayer)       (None, 151, 161, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spect_batch_normalization_1 (Ba (None, 69, 127, 32)  128         spect_conv2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stft_conv2d_1 (Conv2D)          (None, 149, 159, 32) 320         stft_input_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spect_conv2d_2 (Conv2D)         (None, 67, 125, 32)  9248        spect_batch_normalization_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stft_batch_normalization_1 (Bat (None, 149, 159, 32) 128         stft_conv2d_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spect_batch_normalization_2 (Ba (None, 67, 125, 32)  128         spect_conv2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stft_conv2d_2 (Conv2D)          (None, 147, 157, 32) 9248        stft_batch_normalization_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "spect_conv2d_3 (Conv2D)         (None, 34, 63, 32)   25632       spect_batch_normalization_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stft_batch_normalization_2 (Bat (None, 147, 157, 32) 128         stft_conv2d_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spect_dropout_1 (Dropout)       (None, 34, 63, 32)   0           spect_conv2d_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stft_conv2d_3 (Conv2D)          (None, 74, 79, 32)   25632       stft_batch_normalization_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "spect_conv2d_4 (Conv2D)         (None, 32, 61, 64)   18496       spect_dropout_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stft_dropout_1 (Dropout)        (None, 74, 79, 32)   0           stft_conv2d_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spect_batch_normalization_3 (Ba (None, 32, 61, 64)   256         spect_conv2d_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stft_conv2d_4 (Conv2D)          (None, 72, 77, 64)   18496       stft_dropout_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spect_conv2d_5 (Conv2D)         (None, 30, 59, 64)   36928       spect_batch_normalization_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stft_batch_normalization_3 (Bat (None, 72, 77, 64)   256         stft_conv2d_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spect_batch_normalization_4 (Ba (None, 30, 59, 64)   256         spect_conv2d_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stft_conv2d_5 (Conv2D)          (None, 70, 75, 64)   36928       stft_batch_normalization_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "spect_conv2d_6 (Conv2D)         (None, 15, 30, 64)   102464      spect_batch_normalization_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stft_batch_normalization_4 (Bat (None, 70, 75, 64)   256         stft_conv2d_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spect_batch_normalization_5 (Ba (None, 15, 30, 64)   256         spect_conv2d_6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stft_conv2d_6 (Conv2D)          (None, 35, 38, 64)   102464      stft_batch_normalization_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "spect_dropout_2 (Dropout)       (None, 15, 30, 64)   0           spect_batch_normalization_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stft_batch_normalization_5 (Bat (None, 35, 38, 64)   256         stft_conv2d_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spect_conv2d_7 (Conv2D)         (None, 12, 27, 128)  131200      spect_dropout_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stft_dropout_2 (Dropout)        (None, 35, 38, 64)   0           stft_batch_normalization_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "spect_batch_normalization_6 (Ba (None, 12, 27, 128)  512         spect_conv2d_7[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stft_conv2d_7 (Conv2D)          (None, 32, 35, 128)  131200      stft_dropout_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spect_flatten_1 (Flatten)       (None, 41472)        0           spect_batch_normalization_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "stft_batch_normalization_6 (Bat (None, 32, 35, 128)  512         stft_conv2d_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spect_dense_1 (Dense)           (None, 32)           1327136     spect_flatten_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stft_flatten_1 (Flatten)        (None, 143360)       0           stft_batch_normalization_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "spect_dropout_3 (Dropout)       (None, 32)           0           spect_dense_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stft_dropout_3 (Dropout)        (None, 143360)       0           stft_flatten_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 143392)       0           spect_dropout_3[0][0]            \n",
      "                                                                 stft_dropout_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           4588576     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 12)           396         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,567,756\n",
      "Trainable params: 6,566,220\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      " - 50s - loss: 1.2559 - acc: 0.6711 - val_loss: 4.1286 - val_acc: 0.5234\n",
      "Epoch 2/250\n",
      " - 41s - loss: 1.0125 - acc: 0.7000 - val_loss: 0.7221 - val_acc: 0.7818\n",
      "Epoch 3/250\n",
      " - 41s - loss: 0.8198 - acc: 0.7489 - val_loss: 1.0622 - val_acc: 0.6970\n",
      "Epoch 4/250\n",
      " - 41s - loss: 0.7870 - acc: 0.7689 - val_loss: 1.0083 - val_acc: 0.7240\n",
      "Epoch 5/250\n",
      " - 41s - loss: 0.6144 - acc: 0.8044 - val_loss: 0.7629 - val_acc: 0.8174\n",
      "Epoch 6/250\n",
      " - 41s - loss: 0.7151 - acc: 0.7800 - val_loss: 0.7143 - val_acc: 0.7689\n",
      "Epoch 7/250\n",
      " - 41s - loss: 0.5866 - acc: 0.8156 - val_loss: 0.7339 - val_acc: 0.7671\n",
      "Epoch 8/250\n",
      " - 41s - loss: 0.7208 - acc: 0.7878 - val_loss: 0.7084 - val_acc: 0.7960\n",
      "Epoch 9/250\n",
      " - 41s - loss: 0.5975 - acc: 0.8211 - val_loss: 0.5823 - val_acc: 0.8113\n",
      "Epoch 10/250\n",
      " - 41s - loss: 0.5778 - acc: 0.8189 - val_loss: 0.5018 - val_acc: 0.8423\n",
      "Epoch 11/250\n",
      " - 42s - loss: 0.6075 - acc: 0.8144 - val_loss: 14.2826 - val_acc: 0.0987\n",
      "Epoch 12/250\n",
      " - 41s - loss: 0.6823 - acc: 0.7967 - val_loss: 0.4628 - val_acc: 0.8592\n",
      "Epoch 13/250\n",
      " - 41s - loss: 0.5494 - acc: 0.8322 - val_loss: 0.4666 - val_acc: 0.8666\n",
      "Epoch 14/250\n",
      " - 41s - loss: 0.5980 - acc: 0.8033 - val_loss: 0.4994 - val_acc: 0.8348\n",
      "Epoch 15/250\n",
      " - 41s - loss: 0.5458 - acc: 0.8322 - val_loss: 0.5337 - val_acc: 0.8307\n",
      "Epoch 16/250\n",
      " - 41s - loss: 0.5115 - acc: 0.8411 - val_loss: 0.6564 - val_acc: 0.7955\n",
      "Epoch 17/250\n",
      " - 41s - loss: 0.5874 - acc: 0.8322 - val_loss: 0.4162 - val_acc: 0.8778\n",
      "Epoch 18/250\n",
      " - 41s - loss: 0.5461 - acc: 0.8344 - val_loss: 0.4736 - val_acc: 0.8579\n",
      "Epoch 19/250\n",
      " - 41s - loss: 0.4695 - acc: 0.8522 - val_loss: 0.3914 - val_acc: 0.8738\n",
      "Epoch 20/250\n",
      " - 41s - loss: 0.4653 - acc: 0.8522 - val_loss: 0.4673 - val_acc: 0.8542\n",
      "Epoch 21/250\n",
      " - 41s - loss: 0.4708 - acc: 0.8656 - val_loss: 0.3729 - val_acc: 0.8848\n",
      "Epoch 22/250\n",
      " - 41s - loss: 0.5090 - acc: 0.8489 - val_loss: 0.4924 - val_acc: 0.8582\n",
      "Epoch 23/250\n",
      " - 41s - loss: 0.4917 - acc: 0.8411 - val_loss: 0.3897 - val_acc: 0.8878\n",
      "Epoch 24/250\n",
      " - 41s - loss: 0.4915 - acc: 0.8544 - val_loss: 0.4424 - val_acc: 0.8667\n",
      "Epoch 25/250\n",
      " - 41s - loss: 0.3861 - acc: 0.8856 - val_loss: 0.3655 - val_acc: 0.8813\n",
      "Epoch 26/250\n",
      " - 41s - loss: 0.4612 - acc: 0.8511 - val_loss: 0.4694 - val_acc: 0.8442\n",
      "Epoch 27/250\n",
      " - 41s - loss: 0.4305 - acc: 0.8744 - val_loss: 0.3814 - val_acc: 0.8839\n",
      "Epoch 28/250\n",
      " - 41s - loss: 0.3748 - acc: 0.8811 - val_loss: 0.4311 - val_acc: 0.8636\n",
      "Epoch 29/250\n",
      " - 41s - loss: 0.3959 - acc: 0.8711 - val_loss: 0.3510 - val_acc: 0.8922\n",
      "Epoch 30/250\n",
      " - 41s - loss: 0.4438 - acc: 0.8656 - val_loss: 0.3583 - val_acc: 0.8922\n",
      "Epoch 31/250\n",
      " - 41s - loss: 0.3871 - acc: 0.8800 - val_loss: 0.3987 - val_acc: 0.8833\n",
      "Epoch 32/250\n",
      " - 41s - loss: 0.4211 - acc: 0.8744 - val_loss: 0.3766 - val_acc: 0.8858\n",
      "Epoch 33/250\n",
      " - 41s - loss: 0.4144 - acc: 0.8733 - val_loss: 0.5121 - val_acc: 0.8460\n",
      "Epoch 34/250\n",
      " - 41s - loss: 0.4151 - acc: 0.8778 - val_loss: 0.4766 - val_acc: 0.8695\n",
      "Epoch 35/250\n",
      " - 41s - loss: 0.3720 - acc: 0.8744 - val_loss: 0.3831 - val_acc: 0.8898\n",
      "Epoch 36/250\n",
      " - 41s - loss: 0.3627 - acc: 0.8867 - val_loss: 0.5015 - val_acc: 0.8639\n",
      "Epoch 37/250\n",
      " - 41s - loss: 0.3807 - acc: 0.8844 - val_loss: 0.3480 - val_acc: 0.8948\n",
      "Epoch 38/250\n",
      " - 41s - loss: 0.3725 - acc: 0.8744 - val_loss: 0.3667 - val_acc: 0.8894\n",
      "Epoch 39/250\n",
      " - 41s - loss: 0.3090 - acc: 0.8867 - val_loss: 0.3212 - val_acc: 0.9048\n",
      "Epoch 40/250\n",
      " - 42s - loss: 0.4163 - acc: 0.8778 - val_loss: 0.3580 - val_acc: 0.8889\n",
      "Epoch 41/250\n",
      " - 41s - loss: 0.2840 - acc: 0.9089 - val_loss: 0.3995 - val_acc: 0.8748\n",
      "Epoch 42/250\n",
      " - 41s - loss: 0.3056 - acc: 0.9022 - val_loss: 0.3740 - val_acc: 0.8838\n",
      "Epoch 43/250\n",
      " - 41s - loss: 0.4178 - acc: 0.8744 - val_loss: 0.3607 - val_acc: 0.8942\n",
      "Epoch 44/250\n",
      " - 41s - loss: 0.3209 - acc: 0.9044 - val_loss: 0.4276 - val_acc: 0.8661\n",
      "Epoch 45/250\n",
      " - 41s - loss: 0.3861 - acc: 0.8822 - val_loss: 0.6396 - val_acc: 0.8029\n",
      "Epoch 46/250\n",
      " - 41s - loss: 0.3423 - acc: 0.8922 - val_loss: 0.3607 - val_acc: 0.8931\n",
      "Epoch 47/250\n",
      " - 41s - loss: 0.3286 - acc: 0.9111 - val_loss: 0.3121 - val_acc: 0.9120\n",
      "Epoch 48/250\n",
      " - 41s - loss: 0.3443 - acc: 0.8933 - val_loss: 0.3103 - val_acc: 0.9053\n",
      "Epoch 49/250\n",
      " - 41s - loss: 0.3487 - acc: 0.8944 - val_loss: 0.3762 - val_acc: 0.8897\n",
      "Epoch 50/250\n",
      " - 41s - loss: 0.3319 - acc: 0.9011 - val_loss: 0.3011 - val_acc: 0.9073\n",
      "Epoch 51/250\n",
      " - 41s - loss: 0.2731 - acc: 0.9144 - val_loss: 0.2829 - val_acc: 0.9138\n",
      "Epoch 52/250\n",
      " - 41s - loss: 0.3186 - acc: 0.9078 - val_loss: 0.3005 - val_acc: 0.9122\n",
      "Epoch 53/250\n",
      " - 41s - loss: 0.2953 - acc: 0.9022 - val_loss: 0.2811 - val_acc: 0.9162\n",
      "Epoch 54/250\n",
      " - 41s - loss: 0.3073 - acc: 0.9044 - val_loss: 0.2956 - val_acc: 0.9117\n",
      "Epoch 55/250\n",
      " - 41s - loss: 0.3399 - acc: 0.8889 - val_loss: 0.3233 - val_acc: 0.9059\n",
      "Epoch 56/250\n",
      " - 41s - loss: 0.2936 - acc: 0.9111 - val_loss: 0.2809 - val_acc: 0.9179\n",
      "Epoch 57/250\n",
      " - 41s - loss: 0.2992 - acc: 0.9067 - val_loss: 0.3117 - val_acc: 0.9051\n",
      "Epoch 58/250\n",
      " - 41s - loss: 0.2836 - acc: 0.9111 - val_loss: 0.2766 - val_acc: 0.9179\n",
      "Epoch 59/250\n",
      " - 41s - loss: 0.3345 - acc: 0.9056 - val_loss: 0.2915 - val_acc: 0.9128\n",
      "Epoch 60/250\n",
      " - 41s - loss: 0.2929 - acc: 0.9167 - val_loss: 0.2994 - val_acc: 0.9109\n",
      "Epoch 61/250\n",
      " - 42s - loss: 0.2883 - acc: 0.9022 - val_loss: 0.2612 - val_acc: 0.9212\n",
      "Epoch 62/250\n",
      " - 41s - loss: 0.2946 - acc: 0.9067 - val_loss: 0.2796 - val_acc: 0.9160\n",
      "Epoch 63/250\n",
      " - 41s - loss: 0.2470 - acc: 0.9200 - val_loss: 0.2845 - val_acc: 0.9163\n",
      "Epoch 64/250\n",
      " - 41s - loss: 0.2483 - acc: 0.9233 - val_loss: 0.2504 - val_acc: 0.9275\n",
      "Epoch 65/250\n",
      " - 41s - loss: 0.3203 - acc: 0.9111 - val_loss: 0.2699 - val_acc: 0.9206\n",
      "Epoch 66/250\n",
      " - 41s - loss: 0.2576 - acc: 0.9144 - val_loss: 0.2646 - val_acc: 0.9222\n",
      "Epoch 67/250\n",
      " - 42s - loss: 0.2768 - acc: 0.9122 - val_loss: 0.3122 - val_acc: 0.9079\n",
      "Epoch 68/250\n",
      " - 41s - loss: 0.2672 - acc: 0.9256 - val_loss: 0.2864 - val_acc: 0.9144\n",
      "Epoch 69/250\n",
      " - 41s - loss: 0.2558 - acc: 0.9200 - val_loss: 0.2715 - val_acc: 0.9189\n",
      "Epoch 70/250\n",
      " - 41s - loss: 0.2008 - acc: 0.9333 - val_loss: 0.2625 - val_acc: 0.9239\n",
      "Epoch 71/250\n",
      " - 42s - loss: 0.2979 - acc: 0.9044 - val_loss: 0.2658 - val_acc: 0.9223\n",
      "Epoch 72/250\n",
      " - 41s - loss: 0.2874 - acc: 0.9044 - val_loss: 0.2593 - val_acc: 0.9214\n",
      "Epoch 73/250\n",
      " - 41s - loss: 0.2229 - acc: 0.9311 - val_loss: 0.2598 - val_acc: 0.9248\n",
      "Epoch 74/250\n",
      " - 41s - loss: 0.1990 - acc: 0.9411 - val_loss: 0.2438 - val_acc: 0.9304\n",
      "Epoch 75/250\n",
      " - 41s - loss: 0.2481 - acc: 0.9189 - val_loss: 0.2730 - val_acc: 0.9153\n",
      "Epoch 76/250\n",
      " - 41s - loss: 0.1968 - acc: 0.9389 - val_loss: 0.2587 - val_acc: 0.9228\n",
      "Epoch 77/250\n",
      " - 41s - loss: 0.2605 - acc: 0.9233 - val_loss: 0.2497 - val_acc: 0.9251\n",
      "Epoch 78/250\n",
      " - 42s - loss: 0.2388 - acc: 0.9267 - val_loss: 0.2571 - val_acc: 0.9234\n",
      "Epoch 79/250\n",
      " - 41s - loss: 0.2850 - acc: 0.9222 - val_loss: 0.2641 - val_acc: 0.9207\n",
      "Epoch 80/250\n",
      " - 41s - loss: 0.2400 - acc: 0.9200 - val_loss: 0.2514 - val_acc: 0.9288\n",
      "Epoch 81/250\n",
      " - 41s - loss: 0.1917 - acc: 0.9389 - val_loss: 0.2409 - val_acc: 0.9297\n",
      "Epoch 82/250\n",
      " - 41s - loss: 0.2527 - acc: 0.9300 - val_loss: 0.2920 - val_acc: 0.9135\n",
      "Epoch 83/250\n",
      " - 41s - loss: 0.1902 - acc: 0.9433 - val_loss: 0.2443 - val_acc: 0.9272\n",
      "Epoch 84/250\n",
      " - 41s - loss: 0.2277 - acc: 0.9278 - val_loss: 0.2466 - val_acc: 0.9245\n",
      "Epoch 85/250\n",
      " - 41s - loss: 0.2546 - acc: 0.9233 - val_loss: 0.2488 - val_acc: 0.9250\n",
      "Epoch 86/250\n",
      " - 41s - loss: 0.1922 - acc: 0.9378 - val_loss: 0.2449 - val_acc: 0.9287\n",
      "Epoch 87/250\n",
      " - 41s - loss: 0.1988 - acc: 0.9500 - val_loss: 0.2396 - val_acc: 0.9295\n",
      "Epoch 88/250\n",
      " - 41s - loss: 0.2736 - acc: 0.9156 - val_loss: 0.2526 - val_acc: 0.9257\n",
      "Epoch 89/250\n",
      " - 41s - loss: 0.2032 - acc: 0.9389 - val_loss: 0.2501 - val_acc: 0.9269\n",
      "Epoch 90/250\n",
      " - 41s - loss: 0.2087 - acc: 0.9367 - val_loss: 0.2464 - val_acc: 0.9269\n",
      "Epoch 91/250\n",
      " - 41s - loss: 0.1848 - acc: 0.9533 - val_loss: 0.2529 - val_acc: 0.9250\n",
      "Epoch 92/250\n",
      " - 41s - loss: 0.2068 - acc: 0.9311 - val_loss: 0.2395 - val_acc: 0.9287\n",
      "Epoch 93/250\n",
      " - 41s - loss: 0.1829 - acc: 0.9456 - val_loss: 0.2388 - val_acc: 0.9282\n",
      "Epoch 94/250\n",
      " - 41s - loss: 0.2228 - acc: 0.9356 - val_loss: 0.2460 - val_acc: 0.9235\n",
      "Epoch 95/250\n",
      " - 41s - loss: 0.2209 - acc: 0.9300 - val_loss: 0.2369 - val_acc: 0.9284\n",
      "Epoch 96/250\n",
      " - 41s - loss: 0.1732 - acc: 0.9489 - val_loss: 0.2417 - val_acc: 0.9273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/250\n",
      " - 41s - loss: 0.2406 - acc: 0.9322 - val_loss: 0.2360 - val_acc: 0.9267\n",
      "Epoch 98/250\n",
      " - 41s - loss: 0.2236 - acc: 0.9278 - val_loss: 0.2663 - val_acc: 0.9275\n",
      "Epoch 99/250\n",
      " - 41s - loss: 0.2166 - acc: 0.9400 - val_loss: 0.2420 - val_acc: 0.9279\n",
      "Epoch 100/250\n",
      " - 41s - loss: 0.2128 - acc: 0.9289 - val_loss: 0.2592 - val_acc: 0.9229\n",
      "Epoch 101/250\n",
      " - 41s - loss: 0.1707 - acc: 0.9444 - val_loss: 0.2478 - val_acc: 0.9260\n",
      "Epoch 102/250\n",
      " - 41s - loss: 0.1823 - acc: 0.9356 - val_loss: 0.2352 - val_acc: 0.9317\n",
      "Epoch 103/250\n",
      " - 41s - loss: 0.1690 - acc: 0.9533 - val_loss: 0.2329 - val_acc: 0.9301\n",
      "Epoch 104/250\n",
      " - 41s - loss: 0.2085 - acc: 0.9289 - val_loss: 0.2383 - val_acc: 0.9294\n",
      "Epoch 105/250\n",
      " - 41s - loss: 0.1887 - acc: 0.9400 - val_loss: 0.2391 - val_acc: 0.9289\n",
      "Epoch 106/250\n",
      " - 41s - loss: 0.2126 - acc: 0.9322 - val_loss: 0.2334 - val_acc: 0.9340\n",
      "Epoch 107/250\n",
      " - 41s - loss: 0.1670 - acc: 0.9500 - val_loss: 0.2284 - val_acc: 0.9337\n",
      "Epoch 108/250\n",
      " - 41s - loss: 0.1721 - acc: 0.9544 - val_loss: 0.2448 - val_acc: 0.9275\n",
      "Epoch 109/250\n",
      " - 41s - loss: 0.2018 - acc: 0.9400 - val_loss: 0.2277 - val_acc: 0.9323\n",
      "Epoch 110/250\n",
      " - 41s - loss: 0.1803 - acc: 0.9378 - val_loss: 0.2330 - val_acc: 0.9298\n",
      "Epoch 111/250\n",
      " - 41s - loss: 0.1680 - acc: 0.9522 - val_loss: 0.2346 - val_acc: 0.9304\n",
      "Epoch 112/250\n",
      " - 41s - loss: 0.2030 - acc: 0.9311 - val_loss: 0.2411 - val_acc: 0.9313\n",
      "Epoch 113/250\n",
      " - 41s - loss: 0.1611 - acc: 0.9478 - val_loss: 0.2421 - val_acc: 0.9273\n",
      "Epoch 114/250\n",
      " - 41s - loss: 0.2203 - acc: 0.9244 - val_loss: 0.2335 - val_acc: 0.9297\n",
      "Epoch 115/250\n",
      " - 41s - loss: 0.1971 - acc: 0.9522 - val_loss: 0.2405 - val_acc: 0.9273\n",
      "Epoch 116/250\n",
      " - 41s - loss: 0.1875 - acc: 0.9389 - val_loss: 0.2448 - val_acc: 0.9266\n",
      "Epoch 117/250\n",
      " - 41s - loss: 0.2183 - acc: 0.9278 - val_loss: 0.2357 - val_acc: 0.9325\n",
      "Epoch 118/250\n",
      " - 41s - loss: 0.1475 - acc: 0.9500 - val_loss: 0.2428 - val_acc: 0.9269\n",
      "Epoch 119/250\n",
      " - 41s - loss: 0.1823 - acc: 0.9533 - val_loss: 0.2379 - val_acc: 0.9273\n",
      "Epoch 120/250\n",
      " - 41s - loss: 0.2005 - acc: 0.9378 - val_loss: 0.2369 - val_acc: 0.9267\n",
      "Epoch 121/250\n",
      " - 42s - loss: 0.1651 - acc: 0.9467 - val_loss: 0.2294 - val_acc: 0.9315\n",
      "Epoch 122/250\n",
      " - 41s - loss: 0.2091 - acc: 0.9389 - val_loss: 0.2378 - val_acc: 0.9297\n",
      "Epoch 123/250\n",
      " - 41s - loss: 0.1790 - acc: 0.9544 - val_loss: 0.2319 - val_acc: 0.9312\n",
      "Epoch 124/250\n",
      " - 41s - loss: 0.2184 - acc: 0.9333 - val_loss: 0.2295 - val_acc: 0.9325\n",
      "Epoch 125/250\n",
      " - 41s - loss: 0.1635 - acc: 0.9433 - val_loss: 0.2272 - val_acc: 0.9325\n",
      "Epoch 126/250\n",
      " - 41s - loss: 0.1560 - acc: 0.9533 - val_loss: 0.2221 - val_acc: 0.9344\n",
      "Epoch 127/250\n",
      " - 41s - loss: 0.2187 - acc: 0.9467 - val_loss: 0.2326 - val_acc: 0.9287\n",
      "Epoch 128/250\n",
      " - 41s - loss: 0.1871 - acc: 0.9400 - val_loss: 0.2340 - val_acc: 0.9309\n",
      "Epoch 129/250\n",
      " - 41s - loss: 0.1566 - acc: 0.9478 - val_loss: 0.2232 - val_acc: 0.9348\n",
      "Epoch 130/250\n",
      " - 41s - loss: 0.1713 - acc: 0.9400 - val_loss: 0.2258 - val_acc: 0.9341\n",
      "Epoch 131/250\n",
      " - 41s - loss: 0.2428 - acc: 0.9267 - val_loss: 0.2316 - val_acc: 0.9332\n",
      "Epoch 132/250\n",
      " - 41s - loss: 0.1895 - acc: 0.9500 - val_loss: 0.2388 - val_acc: 0.9323\n",
      "Epoch 133/250\n",
      " - 41s - loss: 0.1575 - acc: 0.9467 - val_loss: 0.2320 - val_acc: 0.9320\n",
      "Epoch 134/250\n",
      " - 41s - loss: 0.2249 - acc: 0.9322 - val_loss: 0.2408 - val_acc: 0.9284\n",
      "Epoch 135/250\n",
      " - 41s - loss: 0.1795 - acc: 0.9511 - val_loss: 0.2316 - val_acc: 0.9334\n",
      "Epoch 136/250\n",
      " - 41s - loss: 0.1794 - acc: 0.9344 - val_loss: 0.2348 - val_acc: 0.9295\n",
      "Epoch 137/250\n",
      " - 42s - loss: 0.1743 - acc: 0.9600 - val_loss: 0.2302 - val_acc: 0.9326\n",
      "Epoch 138/250\n",
      " - 41s - loss: 0.2461 - acc: 0.9333 - val_loss: 0.2311 - val_acc: 0.9334\n",
      "Epoch 139/250\n",
      " - 41s - loss: 0.1717 - acc: 0.9500 - val_loss: 0.2249 - val_acc: 0.9340\n",
      "Epoch 140/250\n",
      " - 41s - loss: 0.1947 - acc: 0.9411 - val_loss: 0.2301 - val_acc: 0.9320\n",
      "Epoch 141/250\n",
      " - 41s - loss: 0.1551 - acc: 0.9533 - val_loss: 0.2265 - val_acc: 0.9323\n",
      "Epoch 142/250\n",
      " - 41s - loss: 0.1535 - acc: 0.9500 - val_loss: 0.2271 - val_acc: 0.9332\n",
      "Epoch 143/250\n",
      " - 41s - loss: 0.2005 - acc: 0.9411 - val_loss: 0.2289 - val_acc: 0.9328\n",
      "Epoch 144/250\n",
      " - 41s - loss: 0.1998 - acc: 0.9456 - val_loss: 0.2341 - val_acc: 0.9295\n",
      "Epoch 145/250\n",
      " - 41s - loss: 0.1548 - acc: 0.9544 - val_loss: 0.2302 - val_acc: 0.9326\n",
      "Epoch 146/250\n",
      " - 41s - loss: 0.1744 - acc: 0.9533 - val_loss: 0.2283 - val_acc: 0.9338\n",
      "Epoch 147/250\n",
      " - 41s - loss: 0.1419 - acc: 0.9567 - val_loss: 0.2302 - val_acc: 0.9329\n",
      "Epoch 148/250\n",
      " - 41s - loss: 0.1780 - acc: 0.9544 - val_loss: 0.2249 - val_acc: 0.9359\n",
      "Epoch 149/250\n",
      " - 41s - loss: 0.1879 - acc: 0.9411 - val_loss: 0.2261 - val_acc: 0.9342\n",
      "Epoch 150/250\n",
      " - 41s - loss: 0.1629 - acc: 0.9456 - val_loss: 0.2253 - val_acc: 0.9335\n",
      "Epoch 151/250\n",
      " - 41s - loss: 0.1668 - acc: 0.9556 - val_loss: 0.2250 - val_acc: 0.9338\n",
      "Epoch 152/250\n",
      " - 42s - loss: 0.1538 - acc: 0.9578 - val_loss: 0.2256 - val_acc: 0.9342\n",
      "Epoch 153/250\n",
      " - 41s - loss: 0.1470 - acc: 0.9578 - val_loss: 0.2226 - val_acc: 0.9344\n",
      "Epoch 154/250\n",
      " - 41s - loss: 0.1462 - acc: 0.9578 - val_loss: 0.2244 - val_acc: 0.9350\n",
      "Epoch 155/250\n",
      " - 41s - loss: 0.1797 - acc: 0.9433 - val_loss: 0.2257 - val_acc: 0.9338\n",
      "Epoch 156/250\n",
      " - 41s - loss: 0.1530 - acc: 0.9533 - val_loss: 0.2244 - val_acc: 0.9341\n",
      "Epoch 157/250\n",
      " - 41s - loss: 0.1704 - acc: 0.9467 - val_loss: 0.2256 - val_acc: 0.9341\n",
      "Epoch 158/250\n",
      " - 41s - loss: 0.1730 - acc: 0.9478 - val_loss: 0.2207 - val_acc: 0.9342\n",
      "Epoch 159/250\n",
      " - 41s - loss: 0.1422 - acc: 0.9567 - val_loss: 0.2204 - val_acc: 0.9356\n",
      "Epoch 160/250\n",
      " - 41s - loss: 0.1938 - acc: 0.9444 - val_loss: 0.2206 - val_acc: 0.9365\n",
      "Epoch 161/250\n",
      " - 41s - loss: 0.1559 - acc: 0.9544 - val_loss: 0.2218 - val_acc: 0.9360\n",
      "Epoch 162/250\n",
      " - 41s - loss: 0.1379 - acc: 0.9533 - val_loss: 0.2244 - val_acc: 0.9335\n",
      "Epoch 163/250\n",
      " - 41s - loss: 0.1557 - acc: 0.9511 - val_loss: 0.2201 - val_acc: 0.9359\n",
      "Epoch 164/250\n",
      " - 41s - loss: 0.1739 - acc: 0.9500 - val_loss: 0.2247 - val_acc: 0.9344\n",
      "Epoch 165/250\n",
      " - 41s - loss: 0.1893 - acc: 0.9489 - val_loss: 0.2224 - val_acc: 0.9342\n",
      "Epoch 166/250\n",
      " - 41s - loss: 0.1401 - acc: 0.9567 - val_loss: 0.2208 - val_acc: 0.9348\n",
      "Epoch 167/250\n",
      " - 41s - loss: 0.1283 - acc: 0.9544 - val_loss: 0.2202 - val_acc: 0.9359\n",
      "Epoch 168/250\n",
      " - 41s - loss: 0.1347 - acc: 0.9589 - val_loss: 0.2196 - val_acc: 0.9354\n",
      "Epoch 169/250\n",
      " - 41s - loss: 0.1451 - acc: 0.9567 - val_loss: 0.2194 - val_acc: 0.9356\n",
      "Epoch 170/250\n",
      " - 41s - loss: 0.1954 - acc: 0.9467 - val_loss: 0.2204 - val_acc: 0.9360\n",
      "Epoch 171/250\n",
      " - 41s - loss: 0.1806 - acc: 0.9444 - val_loss: 0.2179 - val_acc: 0.9369\n",
      "Epoch 172/250\n",
      " - 41s - loss: 0.1445 - acc: 0.9544 - val_loss: 0.2239 - val_acc: 0.9338\n",
      "Epoch 173/250\n",
      " - 41s - loss: 0.1304 - acc: 0.9567 - val_loss: 0.2206 - val_acc: 0.9356\n",
      "Epoch 174/250\n",
      " - 41s - loss: 0.2149 - acc: 0.9311 - val_loss: 0.2188 - val_acc: 0.9345\n",
      "Epoch 175/250\n",
      " - 41s - loss: 0.1451 - acc: 0.9633 - val_loss: 0.2180 - val_acc: 0.9356\n",
      "Epoch 176/250\n",
      " - 42s - loss: 0.1988 - acc: 0.9378 - val_loss: 0.2180 - val_acc: 0.9362\n",
      "Epoch 177/250\n",
      " - 41s - loss: 0.1387 - acc: 0.9556 - val_loss: 0.2150 - val_acc: 0.9379\n",
      "Epoch 178/250\n",
      " - 41s - loss: 0.1713 - acc: 0.9544 - val_loss: 0.2232 - val_acc: 0.9351\n",
      "Epoch 179/250\n",
      " - 41s - loss: 0.1748 - acc: 0.9389 - val_loss: 0.2288 - val_acc: 0.9342\n",
      "Epoch 180/250\n",
      " - 41s - loss: 0.1501 - acc: 0.9556 - val_loss: 0.2264 - val_acc: 0.9338\n",
      "Epoch 181/250\n",
      " - 41s - loss: 0.1706 - acc: 0.9511 - val_loss: 0.2237 - val_acc: 0.9353\n",
      "Epoch 182/250\n",
      " - 41s - loss: 0.1378 - acc: 0.9567 - val_loss: 0.2202 - val_acc: 0.9347\n",
      "Epoch 183/250\n",
      " - 41s - loss: 0.1719 - acc: 0.9522 - val_loss: 0.2224 - val_acc: 0.9356\n",
      "Epoch 184/250\n",
      " - 41s - loss: 0.1434 - acc: 0.9478 - val_loss: 0.2198 - val_acc: 0.9366\n",
      "Epoch 185/250\n",
      " - 41s - loss: 0.1230 - acc: 0.9644 - val_loss: 0.2162 - val_acc: 0.9378\n",
      "Epoch 186/250\n",
      " - 41s - loss: 0.1546 - acc: 0.9544 - val_loss: 0.2203 - val_acc: 0.9359\n",
      "Epoch 187/250\n",
      " - 41s - loss: 0.1874 - acc: 0.9467 - val_loss: 0.2181 - val_acc: 0.9365\n",
      "Epoch 188/250\n",
      " - 41s - loss: 0.1362 - acc: 0.9611 - val_loss: 0.2181 - val_acc: 0.9372\n",
      "Epoch 189/250\n",
      " - 41s - loss: 0.1709 - acc: 0.9511 - val_loss: 0.2182 - val_acc: 0.9375\n",
      "Epoch 190/250\n",
      " - 41s - loss: 0.1807 - acc: 0.9389 - val_loss: 0.2162 - val_acc: 0.9363\n",
      "Epoch 191/250\n",
      " - 41s - loss: 0.1496 - acc: 0.9578 - val_loss: 0.2211 - val_acc: 0.9353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/250\n",
      " - 41s - loss: 0.1315 - acc: 0.9522 - val_loss: 0.2193 - val_acc: 0.9353\n",
      "Epoch 193/250\n",
      " - 41s - loss: 0.1527 - acc: 0.9556 - val_loss: 0.2174 - val_acc: 0.9363\n",
      "Epoch 194/250\n",
      " - 41s - loss: 0.1826 - acc: 0.9522 - val_loss: 0.2163 - val_acc: 0.9365\n",
      "Epoch 195/250\n",
      " - 41s - loss: 0.1465 - acc: 0.9544 - val_loss: 0.2211 - val_acc: 0.9362\n",
      "Epoch 196/250\n",
      " - 41s - loss: 0.1232 - acc: 0.9589 - val_loss: 0.2188 - val_acc: 0.9348\n",
      "Epoch 197/250\n",
      " - 41s - loss: 0.1501 - acc: 0.9578 - val_loss: 0.2163 - val_acc: 0.9365\n",
      "Epoch 198/250\n",
      " - 41s - loss: 0.1420 - acc: 0.9633 - val_loss: 0.2152 - val_acc: 0.9373\n",
      "Epoch 199/250\n",
      " - 41s - loss: 0.1671 - acc: 0.9489 - val_loss: 0.2144 - val_acc: 0.9372\n",
      "Epoch 200/250\n",
      " - 41s - loss: 0.1375 - acc: 0.9611 - val_loss: 0.2140 - val_acc: 0.9373\n",
      "Epoch 201/250\n",
      " - 41s - loss: 0.1445 - acc: 0.9611 - val_loss: 0.2152 - val_acc: 0.9370\n",
      "Epoch 202/250\n",
      " - 41s - loss: 0.1332 - acc: 0.9589 - val_loss: 0.2130 - val_acc: 0.9381\n",
      "Epoch 203/250\n",
      " - 41s - loss: 0.1450 - acc: 0.9600 - val_loss: 0.2146 - val_acc: 0.9367\n",
      "Epoch 204/250\n",
      " - 41s - loss: 0.1090 - acc: 0.9633 - val_loss: 0.2128 - val_acc: 0.9375\n",
      "Epoch 205/250\n",
      " - 41s - loss: 0.1447 - acc: 0.9611 - val_loss: 0.2142 - val_acc: 0.9378\n",
      "Epoch 206/250\n",
      " - 41s - loss: 0.1417 - acc: 0.9578 - val_loss: 0.2140 - val_acc: 0.9370\n",
      "Epoch 207/250\n",
      " - 41s - loss: 0.1523 - acc: 0.9500 - val_loss: 0.2148 - val_acc: 0.9375\n",
      "Epoch 208/250\n",
      " - 41s - loss: 0.1780 - acc: 0.9511 - val_loss: 0.2157 - val_acc: 0.9363\n",
      "Epoch 209/250\n",
      " - 41s - loss: 0.1548 - acc: 0.9556 - val_loss: 0.2143 - val_acc: 0.9370\n",
      "Epoch 210/250\n",
      " - 41s - loss: 0.1527 - acc: 0.9600 - val_loss: 0.2148 - val_acc: 0.9375\n",
      "Epoch 211/250\n",
      " - 41s - loss: 0.1703 - acc: 0.9456 - val_loss: 0.2146 - val_acc: 0.9369\n",
      "Epoch 212/250\n",
      " - 41s - loss: 0.1074 - acc: 0.9622 - val_loss: 0.2136 - val_acc: 0.9370\n",
      "Epoch 213/250\n",
      " - 41s - loss: 0.1771 - acc: 0.9511 - val_loss: 0.2137 - val_acc: 0.9372\n",
      "Epoch 214/250\n",
      " - 41s - loss: 0.1307 - acc: 0.9656 - val_loss: 0.2150 - val_acc: 0.9367\n",
      "Epoch 215/250\n",
      " - 41s - loss: 0.1436 - acc: 0.9644 - val_loss: 0.2141 - val_acc: 0.9369\n",
      "Epoch 216/250\n",
      " - 41s - loss: 0.1592 - acc: 0.9589 - val_loss: 0.2135 - val_acc: 0.9375\n",
      "Epoch 217/250\n",
      " - 41s - loss: 0.1542 - acc: 0.9544 - val_loss: 0.2136 - val_acc: 0.9376\n",
      "Epoch 218/250\n",
      " - 41s - loss: 0.1507 - acc: 0.9511 - val_loss: 0.2142 - val_acc: 0.9375\n",
      "Epoch 219/250\n",
      " - 41s - loss: 0.1265 - acc: 0.9600 - val_loss: 0.2137 - val_acc: 0.9372\n",
      "Epoch 220/250\n",
      " - 41s - loss: 0.1548 - acc: 0.9544 - val_loss: 0.2150 - val_acc: 0.9372\n",
      "Epoch 221/250\n",
      " - 41s - loss: 0.1587 - acc: 0.9489 - val_loss: 0.2160 - val_acc: 0.9370\n",
      "Epoch 222/250\n",
      " - 41s - loss: 0.1563 - acc: 0.9522 - val_loss: 0.2143 - val_acc: 0.9376\n",
      "Epoch 223/250\n",
      " - 41s - loss: 0.1488 - acc: 0.9556 - val_loss: 0.2139 - val_acc: 0.9382\n",
      "Epoch 224/250\n",
      " - 41s - loss: 0.1745 - acc: 0.9500 - val_loss: 0.2151 - val_acc: 0.9370\n",
      "Epoch 225/250\n",
      " - 41s - loss: 0.1290 - acc: 0.9589 - val_loss: 0.2145 - val_acc: 0.9372\n",
      "Epoch 226/250\n",
      " - 41s - loss: 0.1124 - acc: 0.9589 - val_loss: 0.2138 - val_acc: 0.9370\n",
      "Epoch 227/250\n",
      " - 41s - loss: 0.1497 - acc: 0.9578 - val_loss: 0.2137 - val_acc: 0.9369\n",
      "Epoch 228/250\n",
      " - 41s - loss: 0.1261 - acc: 0.9589 - val_loss: 0.2135 - val_acc: 0.9370\n",
      "Epoch 229/250\n",
      " - 41s - loss: 0.1463 - acc: 0.9578 - val_loss: 0.2156 - val_acc: 0.9366\n",
      "Epoch 230/250\n",
      " - 41s - loss: 0.1710 - acc: 0.9567 - val_loss: 0.2136 - val_acc: 0.9372\n",
      "Epoch 231/250\n",
      " - 41s - loss: 0.1474 - acc: 0.9600 - val_loss: 0.2112 - val_acc: 0.9376\n",
      "Epoch 232/250\n",
      " - 41s - loss: 0.1621 - acc: 0.9611 - val_loss: 0.2122 - val_acc: 0.9378\n",
      "Epoch 233/250\n",
      " - 41s - loss: 0.1721 - acc: 0.9444 - val_loss: 0.2125 - val_acc: 0.9375\n",
      "Epoch 234/250\n",
      " - 41s - loss: 0.1799 - acc: 0.9544 - val_loss: 0.2120 - val_acc: 0.9370\n",
      "Epoch 235/250\n",
      " - 41s - loss: 0.1221 - acc: 0.9567 - val_loss: 0.2115 - val_acc: 0.9372\n",
      "Epoch 236/250\n",
      " - 43s - loss: 0.1471 - acc: 0.9567 - val_loss: 0.2113 - val_acc: 0.9390\n",
      "Epoch 237/250\n",
      " - 41s - loss: 0.1675 - acc: 0.9567 - val_loss: 0.2113 - val_acc: 0.9375\n",
      "Epoch 238/250\n",
      " - 41s - loss: 0.1533 - acc: 0.9544 - val_loss: 0.2111 - val_acc: 0.9381\n",
      "Epoch 239/250\n",
      " - 41s - loss: 0.1548 - acc: 0.9644 - val_loss: 0.2114 - val_acc: 0.9381\n",
      "Epoch 240/250\n",
      " - 41s - loss: 0.1434 - acc: 0.9578 - val_loss: 0.2116 - val_acc: 0.9379\n",
      "Epoch 241/250\n",
      " - 41s - loss: 0.1242 - acc: 0.9667 - val_loss: 0.2146 - val_acc: 0.9370\n",
      "Epoch 242/250\n",
      " - 41s - loss: 0.1506 - acc: 0.9511 - val_loss: 0.2117 - val_acc: 0.9375\n",
      "Epoch 243/250\n",
      " - 41s - loss: 0.1303 - acc: 0.9567 - val_loss: 0.2119 - val_acc: 0.9376\n",
      "Epoch 244/250\n",
      " - 41s - loss: 0.1560 - acc: 0.9478 - val_loss: 0.2133 - val_acc: 0.9376\n",
      "Epoch 245/250\n",
      " - 41s - loss: 0.1403 - acc: 0.9544 - val_loss: 0.2121 - val_acc: 0.9378\n",
      "Epoch 246/250\n",
      " - 41s - loss: 0.1553 - acc: 0.9544 - val_loss: 0.2119 - val_acc: 0.9385\n",
      "Epoch 247/250\n",
      " - 41s - loss: 0.1769 - acc: 0.9467 - val_loss: 0.2120 - val_acc: 0.9382\n",
      "Epoch 248/250\n",
      " - 41s - loss: 0.1117 - acc: 0.9678 - val_loss: 0.2137 - val_acc: 0.9373\n",
      "Epoch 249/250\n",
      " - 41s - loss: 0.1564 - acc: 0.9489 - val_loss: 0.2133 - val_acc: 0.9384\n",
      "Epoch 250/250\n",
      " - 41s - loss: 0.1157 - acc: 0.9611 - val_loss: 0.2127 - val_acc: 0.9381\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import concatenate, Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Parameters\n",
    "train_params = {\n",
    "    'x1dim': (71,129),\n",
    "    'x2dim': (151,161),\n",
    "    'batch_size': 6,\n",
    "    'n_classes':12,\n",
    "    'n_channels': 1,\n",
    "    'shuffle': True,\n",
    "    'input_type': 'all',\n",
    "    'augment':True\n",
    "}\n",
    "\n",
    "val_params = {\n",
    "    'x1dim': (71,129),\n",
    "    'x2dim': (151,161),\n",
    "    'batch_size': 6,\n",
    "    'n_classes':12,\n",
    "    'n_channels': 1,\n",
    "    'shuffle': False,\n",
    "    'input_type': 'all',\n",
    "    'augment':False\n",
    "}\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], labels, **train_params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **val_params)\n",
    "\n",
    "spect_model_output = spect_model.get_layer('spect_dropout_3').output\n",
    "stft_model_output = stft_model.get_layer('stft_dropout_3').output\n",
    "\n",
    "concatenated = concatenate([spect_model_output, stft_model_output])\n",
    "x = Dense(32, activation='relu')(concatenated)\n",
    "prediction = Dense(12, activation='softmax', name='prediction')(x)\n",
    "        \n",
    "ensemble_model = Model([spect_model.input, stft_model.input], prediction)\n",
    "\n",
    "\n",
    "ensemble_model.compile(optimizer = 'adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=[\"accuracy\"])\n",
    "\n",
    "ensemble_model.summary()\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.98 ** x)\n",
    "\n",
    "# Train model on dataset\n",
    "history = ensemble_model.fit_generator(generator=training_generator,\n",
    "                                       validation_data=validation_generator,\n",
    "                                       steps_per_epoch=150,\n",
    "                                       epochs=250,\n",
    "                                       verbose=2,\n",
    "                                       callbacks=[annealer]\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('CNN Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('CNN Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model.save('../ml/models/retrained_ensemble_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42844"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
